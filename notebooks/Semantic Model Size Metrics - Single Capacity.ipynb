{"cells":[{"cell_type":"markdown","source":["# **Extracting Semantic Model Memory Size from the Fabric Capacity Metrics App for a Single Capacity**\n","\n","# Check out this [blog post](https://bits2bi.com/2025/03/15/extracting-semantic-model-size-from-the-fabric-capacity-metrics-app) for details about this notebook"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"51c2cae4-96d3-4b82-81fb-7b9bf99eb293"},{"cell_type":"markdown","source":["⚠️ Note\n","The DAX query to extract the semantic model size mentioned in this Notebook was written and tested against the Fabric Capacity Metrics App version 1031 (updated on September 11, 2025). It may not work with older or newer versions, as the semantic model structure and object names are subject to change."],"metadata":{},"id":"5d7947af"},{"cell_type":"code","source":["# Install the latest version of semantic link\n","\n","## ........ UNCOMMENT THE FOLLOWING LINE IF YOU'RE RUNNING SPARK 3.3 OR BELOW OR TO UPDATE THE SEMANTIC LINK TO THE LATEST VERSION ........ ##\n","\n","#%pip install -U semantic-link"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"acee1b7d-1073-4e2c-863d-8a2e5248e446"},{"cell_type":"code","source":["# Import the Semantic Link Python library\n","import sempy.fabric as fabric\n","\n","# Import other libraries and modules\n","from pyspark.sql.functions import lit, current_timestamp, to_date, col"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b9690823-ed66-4141-898f-42cc2cf18d7e"},{"cell_type":"code","source":["# Declare and assign variables\n","\n","## ........ PROVIDE THE NAME OR ID OF YOUR FABRIC CAPACTIY METRICS WORKSPACE, FABRIC CAPACTIY METRICS SEMANTIC MODEL, AND THE CAPACITY ID IN FOLLOWING VARIABLES ........ ##\n","\n","\n","workspace_Name = \"212091bd-0616-4370-91e8-c2b2fcf48b25\"\n","dataset_Name = \"dc9b689e-fb5a-4261-8e09-ffbb80091ce9\"\n","capacity_Id = \"d16efc02-0391-43bd-8841-47a044dd67ce\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"09725a8a-3f72-4376-bb41-baede553ccfc"},{"cell_type":"code","source":["# Construct DAX query\n","dax_query = f\"\"\"\n","// DAX query to return the memory usage statistics for the previous day\n","// for all the semantic models hosted on a capacity\n","DEFINE\n","  // Provide a capacity ID for the MPARAMETER\n","    MPARAMETER 'CapacitiesList' = \"{capacity_Id}\"\n","// Filter the items for Datasets as we only want the memory information for semantic models\n","    VAR __DS0FilterTable =\n","        TREATAS ( {{ \"Dataset\" }}, 'Items'[Item kind] )\n","// Filter for yesterday as today's statistics are not yet final and may change during the day\n","// Always extract the data for the completed days\n","    VAR __DS0FilterTable2 =\n","        TREATAS ( {{ UTCTODAY () - 1 }}, 'Dates'[Day] )\n","// Extract Minimum, Maximum, and Median memory sizes\n","    VAR __DS0Core =\n","        SUMMARIZECOLUMNS (\n","            'Dates'[Day],\n","            Items[Item Id],\n","            Items[Item name],\n","            __DS0FilterTable,\n","            __DS0FilterTable2,\n","            \"MinimumMemoryInGB\", ROUND ( MIN ( 'Max Memory By Item And Hour'[Item size (GB)] ), 4 ),\n","            \"MaximumMemoryInGB\", ROUND ( MAX ( 'Max Memory By Item And Hour'[Item size (GB)] ), 4 ),\n","            \"MedianMemoryInGB\", ROUND ( MEDIAN ( 'Max Memory By Item And Hour'[Item size (GB)] ), 4 )\n","        )\n","\n","EVALUATE\n","__DS0Core\n","\"\"\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8d8d7d93-b046-40e8-85ff-13327fdc669f"},{"cell_type":"code","source":["# Execute DAX query on the semantic model\n","# https://learn.microsoft.com/en-us/python/api/semantic-link-sempy/sempy.fabric?view=semantic-link-python#sempy-fabric-evaluate-dax\n","\n","dax_result = fabric.evaluate_dax(\n","    workspace = workspace_Name, \n","    dataset = dataset_Name,\n","    dax_string = dax_query\n",")\n","\n","display(dax_result)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0edc59e3-7f44-423f-8d34-13ffb2dac843"},{"cell_type":"code","source":["# Convert the DAX result to spark dataframe\n","dax_result_df = spark.createDataFrame(dax_result)\n","\n","# Add the current time as data extraction date\n","dax_result_df = dax_result_df.withColumn(\"ExtractionDate\", lit(current_timestamp()))\n","\n","dax_result_df.printSchema()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b25d2bdf-77ac-49eb-b9ac-6f8fadde7a83"},{"cell_type":"code","source":["# Rename the columns for clarity\n","dax_result_cleaned_df = dax_result_df.withColumnRenamed(\"Dates[Day]\", \"Date\") \\\n","               .withColumn(\"Date\", to_date(col(\"Date\")))\\\n","               .withColumnRenamed(\"Items[Item Id]\", \"SemanticModelID\") \\\n","               .withColumnRenamed(\"Items[Item Name]\", \"SemanticModelName\") \\\n","               .withColumnRenamed(\"[MinimumMemoryInGB]\", \"MinimumMemoryInGB\") \\\n","               .withColumnRenamed(\"[MaximumMemoryInGB]\", \"MaximumMemoryInGB\") \\\n","               .withColumnRenamed(\"[MedianMemoryInGB]\", \"MedianMemoryInGB\")\n","\n","# Total rows\n","print(f\"Total Rows: {dax_result_cleaned_df.count()}\")\n","\n","dax_result_cleaned_df.printSchema()\n","\n","# Show the data\n","display(dax_result_cleaned_df)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c7a2e039-3b55-4858-a174-3be13fa74b45"},{"cell_type":"code","source":["# Append the data to the lakehouse delta table\n","dax_result_cleaned_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"semantic_model_size_metrics\")"],"outputs":[],"execution_count":null,"metadata":{"editable":true,"microsoft":{"language":"python","language_group":"synapse_pyspark"},"run_control":{"frozen":false}},"id":"a323bf9b-38eb-4a5d-9f94-158060c8d39f"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"synapse_pyspark","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"state":{},"version":"0.1"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}