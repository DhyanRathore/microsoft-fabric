{"cells":[{"cell_type":"markdown","source":["# **Extracting Semantic Model Memory Size from the Fabric Capacity Metrics App for Multiple Capacities**\n","\n","# Check out this [blog post](https://bits2bi.com/2025/03/15/extracting-semantic-model-size-from-the-fabric-capacity-metrics-app) for details about this notebook"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"51c2cae4-96d3-4b82-81fb-7b9bf99eb293"},{"cell_type":"markdown","source":["⚠️ Note\n","The DAX query to extract the semantic model size mentioned in this Notebook was written and tested against the Fabric Capacity Metrics App version 1031 (updated on September 11, 2025). It may not work with older or newer versions, as the semantic model structure and object names are subject to change."],"metadata":{},"id":"272ffc6d"},{"cell_type":"code","source":["# Install the latest version of semantic link\n","\n","## ........ UNCOMMENT THE FOLLOWING LINE IF YOU'RE RUNNING SPARK 3.3 OR BELOW OR TO UPDATE THE SEMANTIC LINK TO THE LATEST VERSION ........ ##\n","\n","#%pip install -U semantic-link"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"acee1b7d-1073-4e2c-863d-8a2e5248e446"},{"cell_type":"code","source":["# Import the Semantic Link Python library\n","import sempy.fabric as fabric\n","\n","# Import other libraries and modules\n","from pyspark.sql.functions import lit, current_timestamp, to_date, col\n","\n","import pandas as pd"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b9690823-ed66-4141-898f-42cc2cf18d7e"},{"cell_type":"code","source":["# Declare and assign variables\n","\n","## ........ PROVIDE THE NAME OR ID OF YOUR FABRIC CAPACTIY METRICS WORKSPACE AND FABRIC CAPACTIY METRICS SEMANTIC MODEL ........ ##\n","\n","workspace_Name = \"<WORKSPACE_NAME_OR_ID>\"\n","dataset_Name = \"<SEMANTIC_MODEL_NAME_OR_ID>\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8d8d7d93-b046-40e8-85ff-13327fdc669f"},{"cell_type":"markdown","source":["### Are you a capacity admin who wants to extract semantic model size information from a Fabric Capacity Metric App you've installed?\n","##### - **Yes:** Unfreeze the FROZEN CELL #1\n","##### - **No:** Unfreeze the FROZEN CELL #2\n","\n","**<mark>_These capacities should be accessible from the Fabric Capacity Metric semantic model you specified in the previous cell. This Notebook will not work as-is if the capacities are inaccessible from a single Capacity Metrics App._</mark>**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c339a1d9-b999-4f47-b2d6-a602d4475249"},{"cell_type":"code","source":["## ........ FROZEN CELL #1 ........ ##\n","\n","## Get the list of capacities you have access to. These capacities should be accessible from the Fabric Capacity Metrics semantic model you specified in the previous cell.\n","## The list_capacities() returns a list of capacities to which you have Admin and Contributor rights.\n","\n","## ........ IF YOU'VE CONTRIBUTOR RIGHTS TO A CAPACITY, THEN THE CAPACITY IS NOT ACCESSIBLE FROM THE FABRIC CAPACITY METRIC APP THAT YOU'VE INSTALLED ........ ##\n","## ........ IN THIS CASE, YOU HAVE TO PROVIDE THE LIST OF CAPACITIES MANUALLY, PROCEED TO FROZEN CELL 2 ........ ##\n","\n","# https://learn.microsoft.com/en-us/python/api/semantic-link-sempy/sempy.fabric?view=semantic-link-python#sempy-fabric-list-capacities\n","capacities = fabric.list_capacities()\n","\n","# Keep only the Id column\n","capacities_df = capacities[['Id']]\n","\n","display(capacities_df)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"editable":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"},"run_control":{"frozen":true}},"id":"df8bc439-a5a4-48b9-8702-a86098287861"},{"cell_type":"code","source":["## ........ FROZEN CELL #2 ........ ##\n","\n","## ........ PROVIDE THE LIST OF CAPACITIES TO WHICH YOU'VE RECEIVED ACCESS TO THEIR FABRIC CAPACITY METRICS APP. THESE CAPACITIES SHOULD BE ACCESSIBLE FROM THE FABRIC CAPACITY METRIC SEMANTIC MODEL YOU SPECIFIED IN THE PREVIOUS CELL ........ ##\n","\n","capacities = {\n","    'Id': [\"CAPACITY_ID1\",\"CAPACITY_ID2\",\"CAPACITY_ID3\"]\n","}\n","capacities_df = pd.DataFrame(capacities)\n","\n","display(capacities_df)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"editable":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"},"run_control":{"frozen":true}},"id":"66b177f7-1076-4dca-b05d-2315abed93c1"},{"cell_type":"code","source":["# Define the function to call fabric.evaluate_dax and return the result as a DataFrame\n","def evaluate_dax_and_return_df(capacity_Id):\n","\n","    dax_query = f\"\"\"\n","    // DAX query to return the memory usage statistics for the previous day\n","    // for all the semantic models hosted on a capacity\n","    DEFINE\n","    // Provide a capacity ID for the MPARAMETER\n","        MPARAMETER 'CapacitiesList' = \"{capacity_Id}\"\n","    // Filter the items for Datasets as we only want the memory information for semantic models\n","        VAR __DS0FilterTable =\n","            TREATAS ( {{ \"Dataset\" }}, 'Items'[Item kind] )\n","    // Filter for yesterday as today's statistics are not yet final and may change during the day\n","    // Always extract the data for the completed days\n","        VAR __DS0FilterTable2 =\n","            TREATAS ( {{ UTCTODAY () - 1 }}, 'Dates'[Day] )\n","    // Extract Minimum, Maximum, and Median memory sizes\n","        VAR __DS0Core =\n","            SUMMARIZECOLUMNS (\n","                'Dates'[Day],\n","                Items[Item Id],\n","                Items[Item name],\n","                __DS0FilterTable,\n","                __DS0FilterTable2,\n","                \"MinimumMemoryInGB\", ROUND ( MIN ( 'Max Memory By Item And Hour'[Item size (GB)] ), 4 ),\n","                \"MaximumMemoryInGB\", ROUND ( MAX ( 'Max Memory By Item And Hour'[Item size (GB)] ), 4 ),\n","                \"MedianMemoryInGB\", ROUND ( MEDIAN ( 'Max Memory By Item And Hour'[Item size (GB)] ), 4 )\n","            )\n","\n","    EVALUATE\n","    __DS0Core\n","\"\"\"\n","\n","    # Execute DAX query on the semantic model\n","    # https://learn.microsoft.com/en-us/python/api/semantic-link-sempy/sempy.fabric?view=semantic-link-python#sempy-fabric-evaluate-dax\n","    dax_result = fabric.evaluate_dax(\n","        workspace=workspace_Name,\n","        dataset=dataset_Name,\n","        dax_string=dax_query\n","    )\n","    # Convert the result to a pandas DataFrame\n","    result_df = pd.DataFrame(dax_result)\n","    return result_df\n","\n","# Apply the function to each row and collect the results into a list\n","results = capacities_df['Id'].apply(lambda x: evaluate_dax_and_return_df(x)).tolist()\n","\n","# Combine the list of DataFrames into a single DataFrame, ignoring empty DataFrames\n","combined_dax_result_df = pd.concat([df for df in results if not df.empty], ignore_index=True)\n","\n","# Show the result\n","display(combined_dax_result_df)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0edc59e3-7f44-423f-8d34-13ffb2dac843"},{"cell_type":"code","source":["# Convert the DAX result to spark dataframe\n","dax_result_df = spark.createDataFrame(combined_dax_result_df)\n","\n","# Add the current time as data extraction date\n","dax_result_df = dax_result_df.withColumn(\"ExtractionDate\", lit(current_timestamp()))\n","\n","dax_result_df.printSchema()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b25d2bdf-77ac-49eb-b9ac-6f8fadde7a83"},{"cell_type":"code","source":["# Rename the columns for clarity\n","dax_result_cleaned_df = dax_result_df.withColumnRenamed(\"Dates[Day]\", \"Date\") \\\n","               .withColumn(\"Date\", to_date(col(\"Date\")))\\\n","               .withColumnRenamed(\"Items[Item Id]\", \"SemanticModelID\") \\\n","               .withColumnRenamed(\"Items[Item Name]\", \"SemanticModelName\") \\\n","               .withColumnRenamed(\"[MinimumMemoryInGB]\", \"MinimumMemoryInGB\") \\\n","               .withColumnRenamed(\"[MaximumMemoryInGB]\", \"MaximumMemoryInGB\") \\\n","               .withColumnRenamed(\"[MedianMemoryInGB]\", \"MedianMemoryInGB\")\n","\n","# Total rows\n","print(f\"Total Rows: {dax_result_cleaned_df.count()}\")\n","\n","dax_result_cleaned_df.printSchema()\n","\n","# Show the data\n","display(dax_result_cleaned_df)"],"outputs":[],"execution_count":null,"metadata":{"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c7a2e039-3b55-4858-a174-3be13fa74b45"},{"cell_type":"code","source":["# Append the data to the lakehouse delta table\n","dax_result_cleaned_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"semantic_model_size_metrics\")"],"outputs":[],"execution_count":null,"metadata":{"editable":true,"microsoft":{"language":"python","language_group":"synapse_pyspark"},"run_control":{"frozen":false}},"id":"a323bf9b-38eb-4a5d-9f94-158060c8d39f"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"synapse_pyspark","name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"state":{},"version":"0.1"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}